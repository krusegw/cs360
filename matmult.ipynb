{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "731e4680",
      "metadata": {
        "id": "731e4680"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "#from pycuda.compiler import SourceModule\n",
        "from numba import njit, prange\n",
        "import tensorflow as tf\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0385ac4f",
      "metadata": {
        "id": "0385ac4f"
      },
      "source": [
        "# Create two random matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "632b0cca",
      "metadata": {
        "id": "632b0cca"
      },
      "outputs": [],
      "source": [
        "matrix1 = np.random.rand(400, 300)\n",
        "matrix2 = np.random.rand(300, 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb7dd77f",
      "metadata": {
        "id": "bb7dd77f"
      },
      "source": [
        "# Naive method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51439518",
      "metadata": {
        "id": "51439518"
      },
      "outputs": [],
      "source": [
        "# Ensure the number of columns in matrix1 matches the number of rows in matrix2\n",
        "if matrix1.shape[1] != matrix2.shape[0]:\n",
        "    raise ValueError(\"Matrix dimensions do not match for multiplication\")\n",
        "\n",
        "# Initialize the result matrix with zeros\n",
        "result = np.zeros((matrix1.shape[0], matrix2.shape[1]))\n",
        "\n",
        "# Perform matrix multiplication using nested loops\n",
        "start_time = time.time()\n",
        "\n",
        "for i in range(matrix1.shape[0]):\n",
        "    for j in range(matrix2.shape[1]):\n",
        "        for k in range(matrix1.shape[1]):\n",
        "            result[i][j] += matrix1[i][k] * matrix2[k][j]\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Time taken for matrix multiplication using nested loops:\", end_time - start_time, \"seconds\")\n",
        "\n",
        "print (result[0][0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c86e8da0",
      "metadata": {
        "id": "c86e8da0"
      },
      "source": [
        "# Using jit compilation (and cpu cores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fde9f5aa",
      "metadata": {
        "id": "fde9f5aa"
      },
      "outputs": [],
      "source": [
        "@njit(parallel=True)\n",
        "def matrix_multiply_numba(matrix1, matrix2):\n",
        "    result = np.zeros((matrix1.shape[0], matrix2.shape[1]))\n",
        "    for i in prange(matrix1.shape[0]):\n",
        "        for j in range(matrix2.shape[1]):\n",
        "            for k in range(matrix1.shape[1]):\n",
        "                result[i, j] += matrix1[i, k] * matrix2[k, j]\n",
        "    return result\n",
        "\n",
        "# Perform matrix multiplication using Numba\n",
        "start_time = time.time()\n",
        "result_numba = matrix_multiply_numba(matrix1, matrix2)\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Time taken for matrix multiplication using Numba:\", end_time - start_time, \"seconds\")\n",
        "print(result_numba[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ebda734",
      "metadata": {
        "id": "3ebda734"
      },
      "source": [
        "# Using CUDA jit compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73991a1b",
      "metadata": {
        "id": "73991a1b"
      },
      "outputs": [],
      "source": [
        "from numba import cuda\n",
        "\n",
        "@cuda.jit\n",
        "def matrix_multiply_cuda(matrix1, matrix2, result):\n",
        "    row, col = cuda.grid(2)\n",
        "    if row < result.shape[0] and col < result.shape[1]:\n",
        "        temp = 0\n",
        "        for k in range(matrix1.shape[1]):\n",
        "            temp += matrix1[row, k] * matrix2[k, col]\n",
        "        result[row, col] = temp\n",
        "\n",
        "# Allocate memory on the device\n",
        "matrix1_device = cuda.to_device(matrix1)\n",
        "matrix2_device = cuda.to_device(matrix2)\n",
        "result_device = cuda.device_array((matrix1.shape[0], matrix2.shape[1]))\n",
        "\n",
        "# Define thread and block dimensions\n",
        "threads_per_block = (20, 20)\n",
        "blocks_per_grid_x = (result.shape[0] + threads_per_block[0] - 1) // threads_per_block[0]\n",
        "blocks_per_grid_y = (result.shape[1] + threads_per_block[1] - 1) // threads_per_block[1]\n",
        "blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
        "\n",
        "# Perform matrix multiplication using CUDA\n",
        "start_time = time.time()\n",
        "matrix_multiply_cuda[blocks_per_grid, threads_per_block](matrix1_device, matrix2_device, result_device)\n",
        "cuda.synchronize()\n",
        "end_time = time.time()\n",
        "\n",
        "# Copy the result back to the host\n",
        "result_cuda = result_device.copy_to_host()\n",
        "\n",
        "print(\"Time taken for matrix multiplication using CUDA with Numba:\", end_time - start_time, \"seconds\")\n",
        "print(result_cuda[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "216378d7",
      "metadata": {
        "id": "216378d7"
      },
      "source": [
        "# Using tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee0004f0",
      "metadata": {
        "id": "ee0004f0"
      },
      "outputs": [],
      "source": [
        "# Convert numpy arrays to TensorFlow tensors\n",
        "matrix1_tf = tf.convert_to_tensor(matrix1, dtype=tf.float32)\n",
        "matrix2_tf = tf.convert_to_tensor(matrix2, dtype=tf.float32)\n",
        "\n",
        "# Perform matrix multiplication\n",
        "start_time = time.time()\n",
        "result_tf = tf.matmul(matrix1_tf, matrix2_tf)\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Time taken for matrix multiplication using TensorFlow:\", end_time - start_time, \"seconds\")\n",
        "\n",
        "print (result_tf.numpy().shape)\n",
        "\n",
        "print (result_tf.numpy()[0][0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe24176a",
      "metadata": {
        "id": "fe24176a"
      },
      "source": [
        "# Using cupy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6f14f6d",
      "metadata": {
        "id": "b6f14f6d"
      },
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "\n",
        "# Transfer matrices to GPU\n",
        "matrix1_cupy = cp.asarray(matrix1)\n",
        "matrix2_cupy = cp.asarray(matrix2)\n",
        "\n",
        "# Perform matrix multiplication\n",
        "start_time = time.time()\n",
        "result_cupy = cp.matmul(matrix1_cupy, matrix2_cupy)\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Time taken for matrix multiplication using CuPy:\", end_time - start_time, \"seconds\")\n",
        "\n",
        "# Transfer result back to CPU and print the first element\n",
        "result_cupy_cpu = cp.asnumpy(result_cupy)\n",
        "print(result_cupy_cpu[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4a18767",
      "metadata": {
        "id": "b4a18767"
      },
      "outputs": [],
      "source": [
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "\n",
        "# Define the CUDA kernel for matrix multiplication\n",
        "kernel_code = \"\"\"\n",
        "__global__ void matrix_multiply(float *matrix1, float *matrix2, float *result, int width1, int height1, int width2) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < height1 && col < width2) {\n",
        "        float temp = 0;\n",
        "        for (int k = 0; k < width1; ++k) {\n",
        "            temp += matrix1[row * width1 + k] * matrix2[k * width2 + col];\n",
        "        }\n",
        "        result[row * width2 + col] = temp;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Compile the kernel\n",
        "mod = SourceModule(kernel_code)\n",
        "matrix_multiply = mod.get_function(\"matrix_multiply\")\n",
        "\n",
        "# Transfer matrices to GPU\n",
        "matrix1_gpu = cuda.mem_alloc(matrix1.nbytes)\n",
        "matrix2_gpu = cuda.mem_alloc(matrix2.nbytes)\n",
        "result_gpu = cuda.mem_alloc(result.nbytes)\n",
        "\n",
        "cuda.memcpy_htod(matrix1_gpu, matrix1)\n",
        "cuda.memcpy_htod(matrix2_gpu, matrix2)\n",
        "\n",
        "# Define thread and block dimensions\n",
        "threads_per_block = (20, 20, 1)\n",
        "blocks_per_grid_x = (result.shape[1] + threads_per_block[0] - 1) // threads_per_block[0]\n",
        "blocks_per_grid_y = (result.shape[0] + threads_per_block[1] - 1) // threads_per_block[1]\n",
        "blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y, 1)\n",
        "\n",
        "# Perform matrix multiplication using PyCUDA\n",
        "start_time = time.time()\n",
        "matrix_multiply(matrix1_gpu, matrix2_gpu, result_gpu,\n",
        "                np.int32(matrix1.shape[1]), np.int32(matrix1.shape[0]), np.int32(matrix2.shape[1]),\n",
        "                block=threads_per_block, grid=blocks_per_grid)\n",
        "cuda.Context.synchronize()\n",
        "end_time = time.time()\n",
        "\n",
        "# Copy the result back to the host\n",
        "result_pycuda = np.empty_like(result)\n",
        "cuda.memcpy_dtoh(result_pycuda, result_gpu)\n",
        "\n",
        "print(\"Time taken for matrix multiplication using PyCUDA:\", end_time - start_time, \"seconds\")\n",
        "print(result_pycuda[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94f61be3",
      "metadata": {
        "id": "94f61be3"
      },
      "outputs": [],
      "source": [
        "! \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\Common7\\Tools\\vsdevcmd.bat\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17a8e62e",
      "metadata": {
        "id": "17a8e62e"
      },
      "outputs": [],
      "source": [
        "from cuda import cuda, nvrtc\n",
        "import numpy as np\n",
        "\n",
        "# Define the CUDA kernel for matrix multiplication\n",
        "kernel_code = \"\"\"\n",
        "extern \"C\" __global__\n",
        "void matrix_multiply(const float *matrix1, const float *matrix2, float *result, int width1, int height1, int width2) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < height1 && col < width2) {\n",
        "        float temp = 0;\n",
        "        for (int k = 0; k < width1; ++k) {\n",
        "            temp += matrix1[row * width1 + k] * matrix2[k * width2 + col];\n",
        "        }\n",
        "        result[row * width2 + col] = temp;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Compile the kernel\n",
        "prog = nvrtc.nvrtcCreateProgram(kernel_code, \"matrix_multiply.cu\", 0, [], [])\n",
        "nvrtc.nvrtcCompileProgram(prog, [])\n",
        "ptx = nvrtc.nvrtcGetPTX(prog)\n",
        "\n",
        "# Load the module and get the kernel function\n",
        "module = cuda.cuModuleLoadData(ptx)\n",
        "matrix_multiply = cuda.cuModuleGetFunction(module, \"matrix_multiply\")\n",
        "\n",
        "# Allocate memory on the device\n",
        "matrix1_device = cuda.cuMemAlloc(matrix1.nbytes)\n",
        "matrix2_device = cuda.cuMemAlloc(matrix2.nbytes)\n",
        "result_device = cuda.cuMemAlloc(result.nbytes)\n",
        "\n",
        "cuda.cuMemcpyHtoD(matrix1_device, matrix1.tobytes(), matrix1.nbytes)\n",
        "cuda.cuMemcpyHtoD(matrix2_device, matrix2.tobytes(), matrix2.nbytes)\n",
        "\n",
        "# Define thread and block dimensions\n",
        "threads_per_block = (20, 20, 1)\n",
        "blocks_per_grid_x = (result.shape[1] + threads_per_block[0] - 1) // threads_per_block[0]\n",
        "blocks_per_grid_y = (result.shape[0] + threads_per_block[1] - 1) // threads_per_block[1]\n",
        "blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y, 1)\n",
        "\n",
        "# Perform matrix multiplication using CUDA\n",
        "start_time = time.time()\n",
        "cuda.cuLaunchKernel(matrix_multiply,\n",
        "                    blocks_per_grid[0], blocks_per_grid[1], blocks_per_grid[2],\n",
        "                    threads_per_block[0], threads_per_block[1], threads_per_block[2],\n",
        "                    0, 0,\n",
        "                    (matrix1_device, matrix2_device, result_device,\n",
        "                     np.int32(matrix1.shape[1]), np.int32(matrix1.shape[0]), np.int32(matrix2.shape[1])),\n",
        "                    0)\n",
        "cuda.cuCtxSynchronize()\n",
        "end_time = time.time()\n",
        "\n",
        "# Copy the result back to the host\n",
        "result_cuda_python = np.empty_like(result)\n",
        "cuda.cuMemcpyDtoH(result_cuda_python, result_device, result.nbytes)\n",
        "\n",
        "print(\"Time taken for matrix multiplication using cuda-python:\", end_time - start_time, \"seconds\")\n",
        "print(result_cuda_python[0][0])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}